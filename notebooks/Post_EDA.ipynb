{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYq5mYioYtrT"
      },
      "source": [
        "# Post Exploratory Data Analysis (Post-EDA)\n",
        "We perform Post-EDA to confirm the data cleaning worked properly and the dataset is ready for modeling. This includes checking for missing values, duplicates, label distributions, and token lengths (ensuring texts are truncated to 128 tokens). We also review sample texts with labels to verify data quality and consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juGn5Y45Y9QO"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e2j0lmA1Y3PF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuOGCxS3Y_40"
      },
      "source": [
        "Load processed dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rKNrmmHMY7oI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/combined_train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ3_O38kZLcO"
      },
      "source": [
        "Check total number of samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLBD31g8ZGnh",
        "outputId": "45b218b1-caf8-4a8c-9faf-375f65fc78f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 28454\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8undwSaQZQvg"
      },
      "source": [
        " Check for missing/null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL7uYdW5ZQPx",
        "outputId": "99d9def3-c9c9-4918-b0a9-f401533603b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Missing values per column:\n",
            "text             0\n",
            "emotion_label    0\n",
            "sarcasm_label    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "null_counts = df.isnull().sum()\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(null_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMIESnIAZXlH"
      },
      "source": [
        "Check duplicates by 'text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEQZUMLoZOqX",
        "outputId": "ad647d89-4b99-4bb1-d338-f2a5c0c3a8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Duplicate rows by 'text': 0\n"
          ]
        }
      ],
      "source": [
        "dup_count = df.duplicated(subset=['text']).sum()\n",
        "print(f\"\\nDuplicate rows by 'text': {dup_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2utn3n5Za6x"
      },
      "source": [
        "Check Label distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcmOwy3eZZ7A",
        "outputId": "f728380c-ff8c-4da9-fed8-04b80b904460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Emotion label distribution:\n",
            "emotion_label\n",
            "-1    0.129332\n",
            " 0    0.102938\n",
            " 1    0.024179\n",
            " 2    0.118296\n",
            " 3    0.293491\n",
            " 4    0.040416\n",
            " 5    0.173754\n",
            " 6    0.004006\n",
            " 7    0.113587\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Sarcasm label distribution:\n",
            "sarcasm_label\n",
            "-1    0.870668\n",
            " 0    0.067056\n",
            " 1    0.062276\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEmotion label distribution:\")\n",
        "print(df['emotion_label'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "print(\"\\nSarcasm label distribution:\")\n",
        "print(df['sarcasm_label'].value_counts(normalize=True).sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K03m4rYHZkQ6"
      },
      "source": [
        "Count how many have -1 label (missing label in multitask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm4167MvZfuX",
        "outputId": "152ea90b-6fd0-47e1-d2bb-6c5f6da9984d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Samples with missing emotion label (-1): 3680 (12.93%)\n",
            "Samples with missing sarcasm label (-1): 24774 (87.07%)\n"
          ]
        }
      ],
      "source": [
        "emotion_missing = (df['emotion_label'] == -1).sum()\n",
        "sarcasm_missing = (df['sarcasm_label'] == -1).sum()\n",
        "print(f\"\\nSamples with missing emotion label (-1): {emotion_missing} ({emotion_missing / len(df) * 100:.2f}%)\")\n",
        "print(f\"Samples with missing sarcasm label (-1): {sarcasm_missing} ({sarcasm_missing / len(df) * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwt89YCzZrWp"
      },
      "source": [
        "Text length stats (token count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzynGAeHZnzG",
        "outputId": "89ca49a0-fbdb-4820-cb12-a11e16e7908d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Token count statistics (after cleaning & truncation):\n",
            "Mean: 18.10\n",
            "Median: 17.0\n",
            "Max: 127\n",
            "Min: 1\n"
          ]
        }
      ],
      "source": [
        "# Assuming token count is not precomputed, let's compute approximate token count by splitting on whitespace\n",
        "df['token_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
        "print(\"\\nToken count statistics (after cleaning & truncation):\")\n",
        "print(f\"Mean: {df['token_count'].mean():.2f}\")\n",
        "print(f\"Median: {df['token_count'].median()}\")\n",
        "print(f\"Max: {df['token_count'].max()}\")\n",
        "print(f\"Min: {df['token_count'].min()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zacRZF8mZxFZ"
      },
      "source": [
        "Show sample cleaned texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJhhs_6nZush",
        "outputId": "2078b711-b7dc-4d23-d21a-58adcd4fb33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample cleaned tweets with labels:\n",
            "Text: Did not realize how excited I was to have my Netflix stream from my computer to my TV until the cords to make this happen failed .\n",
            "Emotion Label: 5, Sarcasm Label: -1\n",
            "---\n",
            "Text: Oh yes , I loved it . Was n't the scene with the judge great ?\n",
            "Emotion Label: 3, Sarcasm Label: -1\n",
            "---\n",
            "Text: Bout to be another great day ! !\n",
            "Emotion Label: 3, Sarcasm Label: -1\n",
            "---\n",
            "Text: I kept trying to get back to his lugubrious face , which reclined morosely in his good hand as the guests filled the air around him with cultivated noises .\n",
            "Emotion Label: 5, Sarcasm Label: -1\n",
            "---\n",
            "Text: Bobby Robson ' s delight at having guided his team to another major tournament was coupled with gratitude to the 40 - year-old goalkeeper .\n",
            "Emotion Label: 3, Sarcasm Label: -1\n",
            "---\n",
            "Text: I have plans . I feel sick . What a surprising turn of events .\n",
            "Emotion Label: -1, Sarcasm Label: 1\n",
            "---\n",
            "Text: News about current affairs , documentaries , music , movies , noncommercial ads and so on .\n",
            "Emotion Label: 4, Sarcasm Label: -1\n",
            "---\n",
            "Text: For with God , NOTHING will be impossible ! Luke 1:37 :) #awesome #happiness\n",
            "Emotion Label: 3, Sarcasm Label: -1\n",
            "---\n",
            "Text: wake up to my mom at the front door #ok #what\n",
            "Emotion Label: 7, Sarcasm Label: -1\n",
            "---\n",
            "Text: I know , Janet . I just walked out and forgot it completely . I ' ll go home and get it at noon , all right ?\n",
            "Emotion Label: 5, Sarcasm Label: -1\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSample cleaned tweets with labels:\")\n",
        "sample_df = df.sample(10)[['text', 'emotion_label', 'sarcasm_label']]\n",
        "for idx, row in sample_df.iterrows():\n",
        "    print(f\"Text: {row['text']}\\nEmotion Label: {row['emotion_label']}, Sarcasm Label: {row['sarcasm_label']}\\n---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1BtHC9aaan"
      },
      "source": [
        "## Post-EDA summary\n",
        "\n",
        "- The combined training dataset contains 28,454 samples with no missing values in the text, emotion_label, or sarcasm_label columns, ensuring data completeness.\n",
        "\n",
        "- Duplicate checking by text content revealed zero duplicates, indicating clean and unique samples.\n",
        "\n",
        "- Token count statistics indicate that text length ranges from 1 to 127 tokens, with an average length of about 18 tokens per sample. Note that all texts were truncated to a maximum of 128 tokens during preprocessing to fit model input constraints.\n",
        "\n",
        "- A random sample of 10 tweets with their corresponding emotion and sarcasm labels demonstrates the variety in text content and label distribution.\n",
        "\n",
        "- Overall, the dataset is clean and ready for further modeling, with clear indications of label sparsity in sarcasm detection and mild imbalance across emotion categories. These insights will guide preprocessing and model training strategies."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
